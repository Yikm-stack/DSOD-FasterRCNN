# DSOD-FasterRCNN
## Introduction to the Dataset Used by the Model
### VisDrone2019:
VisDrone2019 is a large-scale dataset for object detection and tracking from an aerial perspective, collected by the AISKYEYE team of the Machine Learning and Data Mining Laboratory at Tianjin University. It was collected from 14 different cities in China, covering various environments such as cities, rural areas, and highways. It includes perspectives under different weather conditions, lighting conditions, as well as different angles and altitudes, which can well reflect the object detection and tracking scenarios in the real world. More than 2.6 million object bounding boxes of interest (such as pedestrians, cars, bicycles, and tricycles) have been manually annotated. At the same time, some important attributes are provided, including scene visibility, object categories, and occlusion situations, with fine annotations. On average, each image contains about 100 object instances, and more than 70% of the objects have a size smaller than 80×80 pixels, which belongs to a typical "dense small object" scenario.
  The core value of the Visdrone dataset lies in its objected design for the detection of dense small objects in drone remote sensing scenarios. The high perspective characteristic of drone aerial photography leads to the characteristics of small object size in the images (most objects are smaller than 64×64 pixels), dense distribution (such as vehicle queues on highways and pedestrian gathering areas on urban streets), and diverse shapes (large differences in the postures of vehicles and pedestrians from different angles). Traditional detection algorithms are prone to miss detections or false detections due to insufficient feature extraction, low anchor box matching efficiency, and inadequate utilization of contextual information.
### DOTAv1.0：
The DOTA v1.0 dataset is a large-scale dataset used for object detection in aerial images, which has high academic and application value. The images in the dataset come from various sources, including Google Earth, GF-2 satellite, and aerial images, etc. They are collected by different sensors and platforms and include both RGB images and grayscale images. The RGB images are from Google Earth and Cyclomedia, while the grayscale images are from the panchromatic bands of GF-2 and JL-1 satellite images. All the images are stored in the "png" format. The object instances are annotated by experts in the field of aerial image interpretation. An arbitrary quadrilateral with 8 degrees of freedom is used for annotation, which can more accurately reflect the actual shape and position of the objects. 
The dataset contains a large number of aerial images with different scenes, lighting conditions, and weather conditions. There are many instances of dense small objects in these images, such as small vehicles densely parked in large parking lots or airplanes densely arranged on airport runways. These images provide rich and diverse samples for the research of dense small object detection algorithms, which helps the model learn the features of dense small objects under different situations and improves the generalization ability of the model.
### PascalVOC2012：
The PASCAL VOC2012 dataset is a very classic and important dataset in the field of computer vision. The images in this dataset come from a wide range of sources, covering various scenes and environments, including daily life scenes, natural landscapes, urban streets, etc., aiming to provide rich and diverse image data for tasks such as object detection, image classification, and semantic segmentation. For each object in the images, its category and the corresponding bounding box coordinates are annotated, precisely locating the position of the object in the image. The objects in the images have different postures, scales, lighting conditions, and occlusion situations. For example, some objects may only show part of their bodies, or they are captured under strong light or in the shadow, which poses higher requirements for object detection and recognition algorithms.
The backgrounds of the images in the dataset are complex and diverse, including natural scenes, urban buildings, etc. The complex backgrounds will interfere with object detection, forcing the model to learn to distinguish between the features of the objects and the background. The dense small object detection model trained on this kind of data can better handle the complex backgrounds in practical applications, improving the detection accuracy and generalization ability.


